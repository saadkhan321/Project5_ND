{
 "metadata": {
  "name": "",
  "signature": "sha256:128a0fe43427db4640faa78df4e58450ccd1e7ff6c551b23b913d18fcb32422c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introduction to Machine Learning - ND_Project 4"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "by Saad Khan 05/25/2015"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import Image\n",
      "Image(filename=('Intro2ML_FinalProject.jpg'), embed=True, width=1000, height=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsK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\nFQzXKwsAQTn0oA//2Q==\n",
       "metadata": {
        "jpeg": {
         "height": 1000,
         "width": 1000
        }
       },
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "<IPython.core.display.Image at 0x161a57f0>"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename=('Udacity.jpg'), embed=True, width=800, height=800)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsK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\nQAUUUUAf/9k=\n",
       "metadata": {
        "jpeg": {
         "height": 800,
         "width": 800
        }
       },
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "<IPython.core.display.Image at 0x16185940>"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Enron Corporation was an American energy, commodities, and services company based in Houston, Texas. Before its bankruptcy on December 2, 2001, Enron employed approximately 20,000 staff and was one of the world's major electricity, natural gas, communications, and pulp and paper companies, with claimed revenues of nearly $111 billion during 2000. Fortune named Enron \"America's Most Innovative Company\" for six consecutive years.\n",
      "\n",
      "The Enron scandal, revealed in October 2001, eventually led to the bankruptcy of the Enron Corporation, an American energy company based in Houston, Texas, and the de facto dissolution of Arthur Andersen, which was one of the five largest audit and accountancy partnerships in the world. In addition to being the largest bankruptcy reorganization in American history at that time, Enron was cited as the biggest audit failure.\n",
      "\n",
      "In the resulting Federal investigation, there was a significant amount of typically confidential information entered into public record, including tens of thousands of emails and detailed financial data for top executives."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE:** ENRON submission free response question are answered as part of this project report"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it.  As part of your answer, give some background on the dataset and how it can be used to answer the project question.  Were there any outliers in the data when you got it, and how did you handle those?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Project Goal"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of the project is to build a person of Interest (POI) identifier, using various machine learning techniques, based on the email messages and financial data made public as a result of the Enron scandal. POIs in this case are people who worked at Enron and were probable suspects for the fraudulent activities performed there which eventually led to its bankruptcy.\n",
      "\n",
      "Machine learning will help predict if a certain person picked at random who worked at Enron was involved in the corporate fraud or not, i.e. if that person is a person of interest (POI) or not. Concepts of machine learning are to be applied to the available dataset and a POI classifier is to be created which would help predict person of interest."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Import statements and loading the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "### basic python import statements\n",
      "\n",
      "import sys\n",
      "import pickle\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import re\n",
      "import string\n",
      "import numpy as np\n",
      "import pprint as pp\n",
      "\n",
      "### to make ipython notebook inline matplotlib graphics for ease of viewing\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "### Access folder functions\n",
      "\n",
      "sys.path.append(\"../tools/\")\n",
      "\n",
      "from feature_format import featureFormat, targetFeatureSplit\n",
      "from tester import test_classifier, dump_classifier_and_data\n",
      "\n",
      "### Load the dictionary containing the dataset\n",
      "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of the important characteristics of the dataset are as follows:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dimensions of the Data Set (Total number of points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Total number of observations/data points in the data set:', len(data_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total number of observations/data points in the data set: 146\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Total number of features available per observation:', sum(len(v) for v in data_dict.itervalues())/len(data_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total number of features available per observation: 21\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Allocation of observations (POIs vs. Non-POIs)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = 0\n",
      "for k, v in data_dict.iteritems():\n",
      "    if(data_dict[k][\"poi\"]==1):\n",
      "        count +=1\n",
      "    else:\n",
      "        continue\n",
      "print 'Number of obervations that have POIs:', count\n",
      "print\n",
      "print 'Number of obervations that do not have POIs:', len(data_dict) - count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of obervations that have POIs: 18\n",
        "\n",
        "Number of obervations that do not have POIs: 128\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Salary and Total payments of some high ups @ Enron"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print'LAY KENNETH L, Salary:',data_dict['LAY KENNETH L']['salary'],',Total payments:',data_dict['LAY KENNETH L']['total_payments']\n",
      "print\n",
      "print'SKILLING JEFFREY K, Salary:',data_dict['SKILLING JEFFREY K']['salary'],', Total payments:',data_dict['LAY KENNETH L']['total_payments']\n",
      "print\n",
      "print'FASTOW ANDREW S: Salary,',data_dict['FASTOW ANDREW S']['salary'],', Total payments:',data_dict['LAY KENNETH L']['total_payments']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LAY KENNETH L, Salary: 1072321 ,Total payments: 103559793\n",
        "\n",
        "SKILLING JEFFREY K, Salary: 1111258 , Total payments: 103559793\n",
        "\n",
        "FASTOW ANDREW S: Salary, 440698 , Total payments: 103559793\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Salaried people @ Enron"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salaried_people = 0\n",
      "for k,v in data_dict.iteritems():\n",
      "    if (data_dict[k][\"salary\"]!= 'NaN'):\n",
      "        salaried_people += 1\n",
      "    else:\n",
      "        continue\n",
      "print 'Number of people salaried @ Enron:', salaried_people"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of people salaried @ Enron: 95\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Outlier Investigation (Detection and Removal / Handling)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Outliers in the data set can result from some malfunction or data entry errors. I analyzed the financial data document 'enron61702insiderpay.pdf' with naked eye without any code and following are the observations that I think are outliers and should be cleaned away as they do not contain any essential information. I handled the outliers using the piece of code I applied in lesson 5 exercise in the format: 'dictionary.pop( key, 0 )'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 2: Remove outliers\n",
      "print 'Wendy Grahm only has the feature of directors fees so I thought to remove this observation'\n",
      "print\n",
      "### pp.pprint(data_dict['GRAMM WENDY L'])\n",
      "data_dict.pop(\"GRAMM WENDY L\", None)\n",
      "print 'Another obvious choice for outlier removal was Eugene Lockhart, did not have value associated with any feature'\n",
      "print\n",
      "### pp.pprint(data_dict['LOCKHART EUGENE E'])\n",
      "data_dict.pop(\"LOCKHART EUGENE E\", None)\n",
      "print 'Bruce Wrobel, like Wendy Grahm only has one feature, exercised stock options, so I removed it'\n",
      "print\n",
      "### pp.pprint(data_dict['WROBEL BRUCE'])\n",
      "data_dict.pop(\"WROBEL BRUCE\", None)\n",
      "print 'THE TRAVEL AGENCY IN THE PARK does not seem to be a POI'\n",
      "print\n",
      "### pp.pprint(data_dict['THE TRAVEL AGENCY IN THE PARK'])\n",
      "data_dict.pop(\"THE TRAVEL AGENCY IN THE PARK\", None)\n",
      "print 'TOTAL is not a particular POI as its the total of all financial features'\n",
      "print\n",
      "### pp.pprint(data_dict['TOTAL'])\n",
      "data_dict.pop(\"TOTAL\", None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wendy Grahm only has the feature of directors fees so I thought to remove this observation\n",
        "\n",
        "Another obvious choice for outlier removal was Eugene Lockhart, did not have value associated with any feature\n",
        "\n",
        "Bruce Wrobel, like Wendy Grahm only has one feature, exercised stock options, so I removed it\n",
        "\n",
        "THE TRAVEL AGENCY IN THE PARK does not seem to be a POI\n",
        "\n",
        "TOTAL is not a particular POI as its the total of all financial features\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As per the link from the Udacity discussion forums http://discussions.udacity.com/t/two-records-financial-values-out-of-sync/8687, I updated the following records that were incorrect/inconsistent."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dict['BELFER ROBERT'] = {'bonus': 'NaN',\n",
      "                              'deferral_payments': 'NaN',\n",
      "                              'deferred_income': -102500,\n",
      "                              'director_fees': 102500,\n",
      "                              'email_address': 'NaN',\n",
      "                              'exercised_stock_options': 'NaN',\n",
      "                              'expenses': 3285,\n",
      "                              'from_messages': 'NaN',\n",
      "                              'from_poi_to_this_person': 'NaN',\n",
      "                              'from_this_person_to_poi': 'NaN',\n",
      "                              'loan_advances': 'NaN',\n",
      "                              'long_term_incentive': 'NaN',\n",
      "                              'other': 'NaN',\n",
      "                              'poi': False,\n",
      "                              'restricted_stock': -44093,\n",
      "                              'restricted_stock_deferred': 44093,\n",
      "                              'salary': 'NaN',\n",
      "                              'shared_receipt_with_poi': 'NaN',\n",
      "                              'to_messages': 'NaN',\n",
      "                              'total_payments': 3285,\n",
      "                              'total_stock_value': 'NaN'}\n",
      "\n",
      "data_dict['BHATNAGAR SANJAY'] = {'bonus': 'NaN',\n",
      "                                 'deferral_payments': 'NaN',\n",
      "                                 'deferred_income': 'NaN',\n",
      "                                 'director_fees': 'NaN',\n",
      "                                 'email_address': 'sanjay.bhatnagar@enron.com',\n",
      "                                 'exercised_stock_options': 15456290,\n",
      "                                 'expenses': 137864,\n",
      "                                 'from_messages': 29,\n",
      "                                 'from_poi_to_this_person': 0,\n",
      "                                 'from_this_person_to_poi': 1,\n",
      "                                 'loan_advances': 'NaN',\n",
      "                                 'long_term_incentive': 'NaN',\n",
      "                                 'other': 'NaN',\n",
      "                                 'poi': False,\n",
      "                                 'restricted_stock': 2604490,\n",
      "                                 'restricted_stock_deferred': -2604490,\n",
      "                                 'salary': 'NaN',\n",
      "                                 'shared_receipt_with_poi': 463,\n",
      "                                 'to_messages': 523,\n",
      "                                 'total_payments': 137864,\n",
      "                                 'total_stock_value': 15456290} "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. What features did you end up using in your POI identifier, and what selection process did you use to pick them?  Did you have to do any scaling?  Why or why not?  As part of the assignment, you should attempt to engineer your own feature that doesn\u2019t come ready-made in the dataset--explain what feature you tried to make, and the rationale behind it.  (You do not necessarily have to use it in the final analysis, only engineer and test it.)  If you used an algorithm like a decision tree, please also give the feature importances of the features that you use."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The feature that I used in the final POI identifier were a combination of the following:\n",
      "\n",
      "- Original features in the dataset\n",
      "- New features created from the original email features\n",
      "- Emails word useddata as features"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optimized Feature Selection/Engineering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section deals with the importance of features in the dataset. The 3 important aspects covered here are as follows:\n",
      "\n",
      "**- Creation of new features:**\n",
      "    - 2 new feature created from the original features in the dataset\n",
      "    - Several text features created from the email archive\n",
      "**- Intelligent selection of features: ** Selection of features was a combination of the following:\n",
      "    - Hand picking the feature form the original dataset\n",
      "    - Using newly created features\n",
      "    - Performing selection techniques from the sklearn library (SelectKBest, SelectPercentile)\n",
      "**- Proper scaling of features (if required): ** Scaling was performed where necessary, using the MinMaxScaler method available in the sklearn library \n",
      "\n",
      "List of all 21 original features in the dataset are as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pp.pprint(data_dict['LAY KENNETH L'].keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['salary',\n",
        " 'to_messages',\n",
        " 'deferral_payments',\n",
        " 'total_payments',\n",
        " 'exercised_stock_options',\n",
        " 'bonus',\n",
        " 'restricted_stock',\n",
        " 'shared_receipt_with_poi',\n",
        " 'restricted_stock_deferred',\n",
        " 'total_stock_value',\n",
        " 'expenses',\n",
        " 'loan_advances',\n",
        " 'from_messages',\n",
        " 'other',\n",
        " 'from_this_person_to_poi',\n",
        " 'poi',\n",
        " 'director_fees',\n",
        " 'deferred_income',\n",
        " 'long_term_incentive',\n",
        " 'email_address',\n",
        " 'from_poi_to_this_person']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Initial Feature Selection (by hand from the original features in the datset)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the ipython code chunk below, multiple features were tested both individually and collectively in order to find the optimal combination of features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 1: Select what features you'll use.\n",
      "### features_list is a list of strings, each of which is a feature name.\n",
      "### The first feature must be \"poi\".\n",
      "\n",
      "### POI label\n",
      "\n",
      "poi = 'poi'\n",
      "\n",
      "### NOTE: features combinations are setup in such a way so that performance can be determined individually\n",
      "\n",
      "### Email features\n",
      "\n",
      "e_feature_1 = 'from_messages'\n",
      "e_feature_2 = 'to_messages'\n",
      "e_feature_3 = 'shared_receipt_with_poi'\n",
      "\n",
      "# e_features_list = [e_feature_1, e_feature_2, e_feature_3]\n",
      "\n",
      "e_features_list = []\n",
      "e_features_list = [e_feature_1]\n",
      "e_features_list = e_features_list + [e_feature_2]\n",
      "e_features_list = e_features_list + [e_feature_3]\n",
      "\n",
      "\n",
      "### Financial features\n",
      "\n",
      "f_feature_1 = 'salary'\n",
      "f_feature_2 = 'bonus'\n",
      "f_feature_3 = 'exercised_stock_options'\n",
      "f_feature_4 = 'total_stock_value'\n",
      "f_feature_5 = 'loan_advances'\n",
      "\n",
      "# f_features_list = [f_feature_1, f_feature_2, f_feature_3, f_feature_4, f_feature_5]\n",
      "\n",
      "f_features_list = []\n",
      "f_features_list = [f_feature_1]\n",
      "f_features_list = f_features_list + [f_feature_2]\n",
      "f_features_list = f_features_list + [f_feature_3]\n",
      "f_features_list = f_features_list + [f_feature_4]\n",
      "f_features_list = f_features_list + [f_feature_5]\n",
      "\n",
      "\n",
      "# fraction_features = ['fraction_from_poi', 'fraction_to_poi']\n",
      "\n",
      "### Combined features\n",
      "\n",
      "#features_list = [poi] + e_features_list + f_features_list\n",
      "\n",
      "features_list =  ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus',\n",
      "                  'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses',\n",
      "                  'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees',\n",
      "                  'to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi',\n",
      "                  'shared_receipt_with_poi']\n",
      "\n",
      "print 'Number of features used from the original data set:', len(features_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features used from the original data set: 20\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Investigation/Relationship of some of the features that were selected by hand"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Few of the features selected from the dataset were plotted to have a general idea about the distribution. Data points marked with red crosses are POIs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = featureFormat(data_dict, features_list )\n",
      "poi, testing_poi_test_features = targetFeatureSplit(data)\n",
      "\n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    plt.scatter(testing_poi_test_features[ii][1], testing_poi_test_features[ii][2], color = 'c')\n",
      "    plt.xlabel('to_messages')\n",
      "    plt.ylabel('shared_receipt_with_poi')\n",
      "   \n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    if poi[ii]:\n",
      "        plt.scatter(testing_poi_test_features[ii][1], testing_poi_test_features[ii][2], color = 'r', marker=\"+\")   \n",
      "        \n",
      "plt.show()\n",
      "\n",
      "\n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    plt.scatter(testing_poi_test_features[ii][0], testing_poi_test_features[ii][2], color = 'c')\n",
      "    plt.xlabel('from_messages')\n",
      "    plt.ylabel('shared_receipt_with_poi')\n",
      "   \n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    if poi[ii]:\n",
      "        plt.scatter(testing_poi_test_features[ii][0], testing_poi_test_features[ii][2], color = 'r', marker=\"+\")   \n",
      "        \n",
      "plt.show()\n",
      "\n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    plt.scatter(testing_poi_test_features[ii][3], testing_poi_test_features[ii][5], color = 'c')\n",
      "    plt.xlabel('salary')\n",
      "    plt.ylabel('bonus')\n",
      "   \n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    if poi[ii]:\n",
      "        plt.scatter(testing_poi_test_features[ii][3], testing_poi_test_features[ii][5], color = 'r', marker=\"+\")   \n",
      "        \n",
      "plt.show()\n",
      "\n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    plt.scatter(testing_poi_test_features[ii][6], testing_poi_test_features[ii][5], color = 'c')\n",
      "    plt.xlabel('exercised_stock_options')\n",
      "    plt.ylabel('bonus')\n",
      "   \n",
      "for ii, pp in enumerate(testing_poi_test_features):\n",
      "    if poi[ii]:\n",
      "        plt.scatter(testing_poi_test_features[ii][6], testing_poi_test_features[ii][5], color = 'r', marker=\"+\")   \n",
      "        \n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEQCAYAAAD2/KAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZGZmhXACMjOzQvx/nyEVeI5kt+sAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x16791588>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEQCAYAAAD2/KAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x167915f8>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEVCAYAAADHKRPdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x17ceab38>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6V4rpQAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1720c7b8>"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "New Feature Creation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1. Fraction to/from POI emails (2 features) - Combination of original features in the dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the exercise quiz in lesson 11, following code was implemented to include 2 new features in the data set namely 'fraction_from_poi' and 'fraction_to_poi'. These features are a combination of 4 original features in the dataset. After creation, features are then stored in the modified feature list, 'my_feature_list' and values for all observations stored in modified data set, 'my_dataset'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Assignment to my_dataset and my_feature_list\n",
      "\n",
      "my_dataset = data_dict\n",
      "my_feature_list = features_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 3: Create new feature(s)\n",
      "#my_feature_list = []\n",
      "#my_dataset = {}\n",
      "\n",
      "### computeFraction function used from lesson 11 exercise\n",
      "\n",
      "def computeFraction(poi_messages, all_messages):\n",
      "    \"\"\" given a number messages to/from POI (numerator) \n",
      "        and number of all messages to/from a person (denominator),\n",
      "        return the fraction of messages to/from that person\n",
      "        that are from/to a POI\n",
      "   \"\"\"\n",
      "\n",
      "\n",
      "    ### you fill in this code, so that it returns either\n",
      "    ###     the fraction of all messages to this person that come from POIs\n",
      "    ###     or\n",
      "    ###     the fraction of all messages from this person that are sent to POIs\n",
      "    ### the same code can be used to compute either quantity\n",
      "\n",
      "    ### beware of \"NaN\" when there is no known email address (and so\n",
      "    ### no filled email features), and integer division!\n",
      "    ### in case of poi_messages or all_messages having \"NaN\" value, return 0.\n",
      "    if (poi_messages == 'NaN') or (all_messages == 'NaN'):\n",
      "        fraction = 0.\n",
      "    else:\n",
      "        fraction = float(poi_messages)/float(all_messages)\n",
      "\n",
      "    return fraction\n",
      "\n",
      "\n",
      "for name in data_dict:\n",
      "    \n",
      "    # print name\n",
      "    data_point = data_dict[name]\n",
      "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
      "    to_messages = data_point[\"to_messages\"]\n",
      "    fraction_from_poi = computeFraction(from_poi_to_this_person, to_messages)\n",
      "    # print fraction_from_poi\n",
      "    \n",
      "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
      "    from_messages = data_point[\"from_messages\"]\n",
      "    fraction_to_poi = computeFraction(from_this_person_to_poi, from_messages)\n",
      "    # print fraction_to_poi\n",
      "    \n",
      "    ### Adding values of new features to the modified dataset, 'my_dataset'\n",
      "    \n",
      "    my_dataset[name]['fraction_from_poi'] = fraction_from_poi\n",
      "    my_dataset[name]['fraction_to_poi'] = fraction_to_poi\n",
      "    \n",
      "print '2 new features, \"fraction_from_poi\" and \"fraction_to_poi\", added to \"my_dataset\"'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 new features, \"fraction_from_poi\" and \"fraction_to_poi\", added to \"my_dataset\"\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Adding new feature to the modified features list, 'my_feature_list'\n",
      "\n",
      "fraction_features = ['fraction_from_poi', 'fraction_to_poi']\n",
      "\n",
      "my_feature_list = features_list + fraction_features\n",
      "\n",
      "print 'Number of features now:', len(my_feature_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features now: 22\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "poi  = \"poi\"\n",
      "\n",
      "poi_fraction_features = [poi, 'fraction_from_poi', 'fraction_to_poi']\n",
      "\n",
      "data = featureFormat(my_dataset, poi_fraction_features)\n",
      "poi, testing_fraction_features = targetFeatureSplit(data)\n",
      "\n",
      "for ii, pp in enumerate(testing_fraction_features):\n",
      "    if testing_fraction_features[ii][0] != 0.0 or testing_fraction_features[ii][1] != 0.0:\n",
      "        plt.scatter(testing_fraction_features[ii][0], testing_fraction_features[ii][1], color = 'c')\n",
      "        plt.xlabel('Fraction of emails this person gets from POI')\n",
      "        plt.ylabel('Fraction of emails this person sends to POI')\n",
      "    else:\n",
      "        continue\n",
      "for ii, pp in enumerate(testing_fraction_features):\n",
      "    if poi[ii] and (testing_fraction_features[ii][0] != 0.0 or testing_fraction_features[ii][1] != 0.0):\n",
      "        plt.scatter(testing_fraction_features[ii][0], testing_fraction_features[ii][1], color = 'r', marker=\"+\")   \n",
      "        \n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEPCAYAAABsj5JaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3lS7ZIKdAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x160f6630>"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE:** The scatter plot represents the fraction of email exchange between Non-POI/POI. Red crosses show the POIs. It can be observed that there is a definite trend that POIs mostly send/receive emails to/from other POIs. People that are non POI tend to send fewer emails as can be seen mostly clustered with fractions closer to 0."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2. Word features from text in the email archives"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function \u2018parseOutText\u2019 was used from the lesson 10 mini-project along with a modified version of the code used to extract email text in lesson 10 mini-project. First it was checked if the observation had valid email address and then for a valid email address, email text was extracted using the \u2018parseOutText\u2019 function. The snowball stemmer for English is already implemented in the \u2018parseOutText\u2019 function. The text features data was extracted and stored in a dictionary, \u2018word_data\u2019. Using words in emails as feature added an additional dimension to the model in creating the POI identifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parseOutText(f):\n",
      "    \"\"\" given an opened email file f, parse out all text below the\n",
      "        metadata block at the top\n",
      "        (in Part 2, you will also add stemming capabilities)\n",
      "        and return a string that contains all the words\n",
      "        in the email (space-separated) \n",
      "        \n",
      "        example use case:\n",
      "        f = open(\"email_file_name.txt\", \"r\")\n",
      "        text = parseOutText(f)\n",
      "        \n",
      "        \"\"\"\n",
      "\n",
      "\n",
      "    f.seek(0)  ### go back to beginning of file (annoying)\n",
      "    all_text = f.read()\n",
      "\n",
      "    ### split off metadata\n",
      "    content = all_text.split(\"X-FileName:\")\n",
      "    words = \"\"\n",
      "    if len(content) > 1:\n",
      "        ### remove punctuation\n",
      "        text_string = content[1].translate(string.maketrans(\"\", \"\"), string.punctuation)\n",
      "\n",
      "        ### project part 2: comment out the line below\n",
      "        #words = text_string\n",
      "\n",
      "        ### split the text string into individual words, stem each word,\n",
      "        ### and append the stemmed word to words (make sure there's a single\n",
      "        ### space between each stemmed word)\n",
      "        \n",
      "        #print text_string\n",
      "        \n",
      "        email_split = text_string.split()\n",
      "    \n",
      "        #print email_split\n",
      "\n",
      "        from nltk.stem.snowball import SnowballStemmer\n",
      "\n",
      "        stemmer = SnowballStemmer(\"english\")\n",
      "        \n",
      "        email_stemmed = []\n",
      "        for n in range(len(email_split)):\n",
      "            email_stemmed.append(stemmer.stem(email_split[n]))\n",
      "        \n",
      "    words = ' '.join(email_stemmed)    \n",
      "    \n",
      "    return words\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE:** Below is the piece of code which is used to identify valid email addresses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "valid_email_id_list = []\n",
      "\n",
      "email_address_path_folder = os.listdir(\"../final_project/emails_by_address/\")\n",
      "\n",
      "test_dataset = my_dataset\n",
      "#observation_removal = []\n",
      "\n",
      "count1 = 0\n",
      "count2 = 0\n",
      "\n",
      "for name in my_dataset:\n",
      "    #k = name\n",
      "    email_name = test_dataset[name]\n",
      "    email_address = email_name[\"email_address\"]\n",
      "    email_address_path = \"from_\" + email_address + \".txt\"\n",
      "    #print email_address, email_address_path\n",
      "    if email_address == 'NaN':\n",
      "        #observation_removal.append(name)\n",
      "        #print 'TO BE REMOVED_1:' ,email_address_path\n",
      "        count1 += 1\n",
      "    \n",
      "    elif email_address_path not in email_address_path_folder:\n",
      "        #observation_removal.append(name)\n",
      "        #print 'TO BE REMOVED_2:' ,email_address_path\n",
      "        count2 += 1\n",
      "    else:\n",
      "        valid_email_id_list.append(email_address)\n",
      "        #print email_address_path\n",
      "    \n",
      "\n",
      "print 'size of the dataset:', len(my_dataset)    \n",
      "print    \n",
      "print 'No of observation that have no email data for word features:', count1 + count2 \n",
      "\n",
      "\n",
      "'''        \n",
      "for n in observation_removal:\n",
      "    test_dataset.pop(n, None)\n",
      "'''            \n",
      "\n",
      "my_dataset = test_dataset       \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "size of the dataset: 141\n",
        "\n",
        "No of observation that have no email data for word features: 55\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print valid_email_id_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['mark.metts@enron.com', 'bill.cordes@enron.com', 'kevin.hannon@enron.com', 'rockford.meyer@enron.com', 'jeffrey.mcmahon@enron.com', 'stanley.horton@enron.com', 'greg.piper@enron.com', 'gene.humphrey@enron.com', 'adam.umanoff@enron.com', 'jeremy.blachman@enron.com', 'marty.sunde@enron.com', 'dana.gibbs@enron.com', 'wes.colwell@enron.com', 's..muller@enron.com', 'charlene.jackson@enron.com', 'rob.walls@enron.com', 'louise.kitchen@enron.com', 'jeffrey.shankman@enron.com', 'rick.bergsieker@enron.com', 'philippe.bibi@enron.com', 'paula.rieker@enron.com', 'sally.beck@enron.com', 'david.haug@enron.com', 'gary.hickerson@enron.com', 'richard.lewis@enron.com', 'robert.hayes@enron.com', 'danny.mccarty@enron.com', 'dan.leff@enron.com', 'john.lavorato@enron.com', 'ken.powers@enron.com', 'james.bannantine@enron.com', 'richard.shapiro@enron.com', 'john.sherriff@enron.com', 'rex.shelby@enron.com', 'joseph.deffner@enron.com', 'greg.whalley@enron.com', 'mike.mcconnell@enron.com', 'jim.piro@enron.com', 'david.delainey@enron.com', 'kenneth.lay@enron.com', 'cindy.olson@enron.com', 'rebecca.mcdonald@enron.com', 'george.mcclellan@enron.com', 'mark.haedicke@enron.com', 'raymond.bowen@enron.com', 'jay.fitzgerald@enron.com', 'michael.moran@enron.com', 'brian.redmond@enron.com', 'tim.belden@enron.com', 'w.duran@enron.com', 'terence.thorn@enron.com', 'tracy.foy@enron.com', 'christopher.calger@enron.com', 'ken.rice@enron.com', 'vince.kaminski@enron.com', 'chip.cox@enron.com', 'jeff.skilling@enron.com', 'jeffrey.sherrick@enron.com', 'mark.pickering@enron.com', 'steven.kean@enron.com', 'kulvinder.fowler@enron.com', 'george.wasaff@enron.com', 'phillip.allen@enron.com', 'vicki.sharp@enron.com', 'michael.brown@enron.com', 'james.hughes@enron.com', 'sanjay.bhatnagar@enron.com', 'rebecca.carter@enron.com', 'john.buchanan@enron.com', 'julia.murray@enron.com', 'kevin.garland@enron.com', 'keith.dodson@enron.com', 'janet.dietrich@enron.com', 'james.derrick@enron.com', 'mark.frevert@enron.com', 'rod.hayslett@enron.com', 'jim.fallon@enron.com', 'mark.koenig@enron.com', 'larry.izzo@enron.com', 'elizabeth.tilney@enron.com', 'a..martin@enron.com', 'rick.buy@enron.com', 'richard.causey@enron.com', 'mitchell.taylor@enron.com', 'jeff.donahue@enron.com', 'ben.glisan@enron.com']\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Final piece of code used to parse email text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from_data = []\n",
      "word_data = []\n",
      "\n",
      "import os\n",
      "import pickle\n",
      "import re\n",
      "import sys\n",
      "import string\n",
      "\n",
      "\n",
      "temp_counter = 0\n",
      "\n",
      "for n in range(len(valid_email_id_list)):\n",
      "    \n",
      "    email_address_folder = \"../final_project/emails_by_address/from_\" + valid_email_id_list[n] + \".txt\"\n",
      "    \n",
      "    #text_file = os.listdir(\"../final_project/emails_by_address/\")\n",
      "    \n",
      "    email_file_path = open(email_address_folder, \"r\")\n",
      "    \n",
      "    for path in email_file_path:\n",
      "        ### only look at first 200 emails when developing\n",
      "        ### once everything is working, remove this line to run over full dataset\n",
      "        temp_counter += 1\n",
      "        if temp_counter < 200:\n",
      "        \n",
      "        \n",
      "            path = os.path.join('..', path[:-1])\n",
      "            #print path\n",
      "            email = open(path, \"r\")\n",
      "\n",
      "            stemmed_email = parseOutText(email)\n",
      "\n",
      "            word_data.append(stemmed_email)\n",
      "            '''\n",
      "            if (name == \"chris\"):\n",
      "                from_data.append(1)\n",
      "            else:\n",
      "                from_data.append(0)\n",
      "            '''\n",
      "            from_data.append(n)\n",
      "\n",
      "            email.close()\n",
      "    \n",
      "print \"emails processed\"\n",
      "#from_sara.close()\n",
      "#from_chris.close()\n",
      "\n",
      "pickle.dump( word_data, open(\"your_word_data.pkl\", \"w\") )\n",
      "pickle.dump( from_data, open(\"your_email_authors.pkl\", \"w\") )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "emails processed\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extract features and labels from dataset for testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = featureFormat(my_dataset, my_feature_list, sort_keys = True)\n",
      "\n",
      "labels, features = targetFeatureSplit(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Python import statements for implementing the classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Vectorizer utility for text features\n",
      "\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "### Feature Scaler utility\n",
      "\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "### Feature Selector utility\n",
      "\n",
      "from sklearn.feature_selection import SelectPercentile, f_classif\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "\n",
      "### Grid Fit/Transform utility\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "### Algorithms\n",
      "\n",
      "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "### Cross Validation utility\n",
      "\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "### Key Performance Indicators/Metrics\n",
      "\n",
      "from sklearn.metrics import precision_score, recall_score, f1_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE:** Going forward, I have implemented different combinations of features, vectorizer, scaler, feature selector and cross validation techniques to evaluate the Key Perfomance Indicators (KPIs) i.e. Precision and Recall along with accuracy and F1-score. I have provided the description for all parameters/features settings for the different combinations I tried to fullfil the requirement in the project rubric."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Combination 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "|Combination|Description|\n",
      "|--|-------------------------------|\n",
      "|**Features selected**|All original features(except email addresses) + fraction features(2 vnew features) = 22|\n",
      "|**Algorithm** |Ada Boost|\n",
      "|**Parameters**|{'n_estimators': [1, 100], 'random_state': [1, 50]}|\n",
      "|**Vectorizer**|Tfidf (stop_words=\"english\", lowercase=True)|\n",
      "|**Scaler**|MinMax|\n",
      "|**Selector**|Select Percentile (f_classif, percentile=10)|\n",
      "|**CV Search**|GridSearchCV|\n",
      "|**CV Generator**|StratifiedShuffleSplit(labels, 10, random_state = 42)|"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "### Combination chunk for vectorizer, scaler and selector\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=10)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "      \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    #word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    #word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    #features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    #features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "        \n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 100], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.88000\tPrecision: 0.75000\tRecall: 0.15000\tF1: 0.25000\tF2: 0.17857\n",
        "\tTotal predictions:  150\tTrue positives:    3\tFalse positives:    1\tFalse negatives:   17\tTrue negatives:  129\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Combination 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- **Features selected :** Original features + fraction features + word features\n",
      "- **Algorithm         :** Ada Boost\n",
      "- **Parameters        :** {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "- **Vectorizer        :** Tfidf (stop_words=\"english\", lowercase=True)\n",
      "- **Scaler            :** MinMax\n",
      "- **Selector          :** Select Percentile (f_classif, percentile=10)\n",
      "- **CV Search         :**  GridSearchCV\n",
      "- **CV Generator      :** StratifiedShuffleSplit(labels, 10, random_state = 42)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "### Combination chunk for vectorizer, scaler and selector\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=10)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "        \n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "       \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 100], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.87333\tPrecision: 1.00000\tRecall: 0.05000\tF1: 0.09524\tF2: 0.06173\n",
        "\tTotal predictions:  150\tTrue positives:    1\tFalse positives:    0\tFalse negatives:   19\tTrue negatives:  130\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Combination 3"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- **Features selected :** Original features + fraction features + word features\n",
      "- **Algorithm         :** Decision Tree\n",
      "- **Parameters        :** {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt')}\n",
      "- **Vectorizer        :** Tfidf (stop_words=\"english\", lowercase=True)\n",
      "- **Scaler            :** MinMax\n",
      "- **Selector          :** Select Percentile (f_classif, percentile=10)\n",
      "- **CV Search         :** GridSearchCV\n",
      "- **CV Generator      :** StratifiedShuffleSplit(labels, 10, random_state = 42)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "### Combination chunk for vectorizer, scaler and selector\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=10)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "\n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'max_features': ('auto', 'sqrt'), 'criterion': ('gini', 'entropy')},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.82667\tPrecision: 0.31250\tRecall: 0.25000\tF1: 0.27778\tF2: 0.26042\n",
        "\tTotal predictions:  150\tTrue positives:    5\tFalse positives:   11\tFalse negatives:   15\tTrue negatives:  119\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Combination 4"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- **Features selected :** Original features + fraction features + word features\n",
      "- **Algorithm         :** Decision Tree\n",
      "- **Parameters        :** {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt')}\n",
      "- **Vectorizer        :** Tfidf (stop_words=\"english\", lowercase=True)\n",
      "- **Scaler            :** MinMax\n",
      "- **Selector          :** Select Percentile (f_classif, percentile=5)\n",
      "- **CV Search         :** GridSearchCV\n",
      "- **CV Generator      :** StratifiedShuffleSplit(labels, 10, random_state = 42)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "### Combination chunk for vectorizer, scaler and selector\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, max_df = 0.5)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=5)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "\n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      " \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'max_features': ('auto', 'sqrt'), 'criterion': ('gini', 'entropy')},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.82000\tPrecision: 0.29412\tRecall: 0.25000\tF1: 0.27027\tF2: 0.25773\n",
        "\tTotal predictions:  150\tTrue positives:    5\tFalse positives:   12\tFalse negatives:   15\tTrue negatives:  118\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Combination 5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- **Features selected :** Original features + fraction features + word features\n",
      "- **Algorithm         :** Decision Tree\n",
      "- **Parameters        :** {'max_features': ('auto', 'sqrt', 'log2'), 'criterion': ('gini', 'entropy')}\n",
      "- **Vectorizer        :** Tfidf (stop_words=\"english\", lowercase=True)\n",
      "- **Scaler            :** MinMax\n",
      "- **Selector          :** Select Percentile (f_classif, percentile=5)\n",
      "- **CV Search         :** GridSearchCV\n",
      "- **CV Generator      :** StratifiedShuffleSplit(labels, 10, random_state = 42)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "### Combination chunk for vectorizer, scaler and selector\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, max_df = 0.5)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=5)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "\n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'max_features': ('auto', 'sqrt', 'log2'), 'criterion': ('gini', 'entropy')},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.85333\tPrecision: 0.41667\tRecall: 0.25000\tF1: 0.31250\tF2: 0.27174\n",
        "\tTotal predictions:  150\tTrue positives:    5\tFalse positives:    7\tFalse negatives:   15\tTrue negatives:  123\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, max_df = 0.5)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=5)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "#count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    '''\n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    #count += 1\n",
      "    #print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.82692\tPrecision: 0.28814\tRecall: 0.08500\tF1: 0.13127\tF2: 0.09895\n",
        "\tTotal predictions: 1300\tTrue positives:   17\tFalse positives:   42\tFalse negatives:  183\tTrue negatives: 1058\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, max_df = 0.5)\n",
      "scaler = MinMaxScaler()\n",
      "selector = SelectPercentile(f_classif, percentile=5)\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "#selector = SelectKBest(f_classif, k=3)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "#count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2')}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    #count += 1\n",
      "    #print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            random_state=None, splitter='best'),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'max_features': ('auto', 'sqrt', 'log2'), 'criterion': ('gini', 'entropy')},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.82333\tPrecision: 0.31429\tRecall: 0.27500\tF1: 0.29333\tF2: 0.28205\n",
        "\tTotal predictions: 1500\tTrue positives:   55\tFalse positives:  120\tFalse negatives:  145\tTrue negatives: 1180\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, max_df = 0.5)\n",
      "scaler = MinMaxScaler()\n",
      "#selector = SelectPercentile(f_classif, percentile=10)\n",
      "skf = StratifiedKFold(labels, n_folds=10)\n",
      "#cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
      "#cv = KFold( len(labels), 6)\n",
      "selector = SelectKBest(f_classif, k=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "#count = 0\n",
      "for train_indices, test_indices in skf:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    #count += 1\n",
      "    #print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GaussianNB()\n",
        "\tAccuracy: 0.81560\tPrecision: 0.30000\tRecall: 0.33333\tF1: 0.31579\tF2: 0.32609\n",
        "\tTotal predictions:  141\tTrue positives:    6\tFalse positives:   14\tFalse negatives:   12\tTrue negatives:  109\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "#selector = SelectPercentile(f_classif, percentile=10)\n",
      "#skf = StratifiedKFold(labels, n_folds=10)\n",
      "#cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
      "cv = KFold( len(labels), 10)\n",
      "selector = SelectKBest(f_classif, k=6)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    #word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    #word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    #features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    #features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "GaussianNB()\n",
        "\tAccuracy: 0.86525\tPrecision: 0.46667\tRecall: 0.38889\tF1: 0.42424\tF2: 0.40230\n",
        "\tTotal predictions:  141\tTrue positives:    7\tFalse positives:    8\tFalse negatives:   11\tTrue negatives:  115\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "#selector = SelectPercentile(f_classif, percentile=10)\n",
      "skf = StratifiedKFold(labels, n_folds=6)\n",
      "#cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
      "#cv = KFold( len(labels), 10)\n",
      "selector = SelectKBest(f_classif, k=4)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in skf:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    \n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 100], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 100], 'random_state': [1, 50], 'algorithm': ['SAMME.R']},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.85106\tPrecision: 0.38462\tRecall: 0.27778\tF1: 0.32258\tF2: 0.29412\n",
        "\tTotal predictions:  141\tTrue positives:    5\tFalse positives:    8\tFalse negatives:   13\tTrue negatives:  115\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=2)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    \n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm': ['SAMME.R']},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.87333\tPrecision: 0.60000\tRecall: 0.15000\tF1: 0.24000\tF2: 0.17647\n",
        "\tTotal predictions:  150\tTrue positives:    3\tFalse positives:    2\tFalse negatives:   17\tTrue negatives:  128\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=2)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    #word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    #word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    #features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    #features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.83333\tPrecision: 0.38095\tRecall: 0.40000\tF1: 0.39024\tF2: 0.39604\n",
        "\tTotal predictions:  150\tTrue positives:    8\tFalse positives:   13\tFalse negatives:   12\tTrue negatives:  117\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=2)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'criterion':['entropy']}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50], 'criterion': ['entropy']},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.80667\tPrecision: 0.28571\tRecall: 0.30000\tF1: 0.29268\tF2: 0.29703\n",
        "\tTotal predictions:  150\tTrue positives:    6\tFalse positives:   15\tFalse negatives:   14\tTrue negatives:  115\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 331
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=2)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.82000\tPrecision: 0.31579\tRecall: 0.30000\tF1: 0.30769\tF2: 0.30303\n",
        "\tTotal predictions:  150\tTrue positives:    6\tFalse positives:   13\tFalse negatives:   14\tTrue negatives:  117\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=3)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.83333\tPrecision: 0.33333\tRecall: 0.25000\tF1: 0.28571\tF2: 0.26316\n",
        "\tTotal predictions:  150\tTrue positives:    5\tFalse positives:   10\tFalse negatives:   15\tTrue negatives:  120\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=4)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.86000\tPrecision: 0.47059\tRecall: 0.40000\tF1: 0.43243\tF2: 0.41237\n",
        "\tTotal predictions:  150\tTrue positives:    8\tFalse positives:    9\tFalse negatives:   12\tTrue negatives:  121\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "skf = StratifiedKFold(labels, n_folds=6)\n",
      "#cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=4)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in skf:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.84397\tPrecision: 0.30000\tRecall: 0.16667\tF1: 0.21429\tF2: 0.18293\n",
        "\tTotal predictions:  141\tTrue positives:    3\tFalse positives:    7\tFalse negatives:   15\tTrue negatives:  116\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 335
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=5)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.82667\tPrecision: 0.33333\tRecall: 0.30000\tF1: 0.31579\tF2: 0.30612\n",
        "\tTotal predictions:  150\tTrue positives:    6\tFalse positives:   12\tFalse negatives:   14\tTrue negatives:  118\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=6)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.84667\tPrecision: 0.28571\tRecall: 0.10000\tF1: 0.14815\tF2: 0.11494\n",
        "\tTotal predictions:  150\tTrue positives:    2\tFalse positives:    5\tFalse negatives:   18\tTrue negatives:  125\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 337
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=4)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    #word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    #word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    #features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    #features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.86667\tPrecision: 0.50000\tRecall: 0.30000\tF1: 0.37500\tF2: 0.32609\n",
        "\tTotal predictions:  150\tTrue positives:    6\tFalse positives:    6\tFalse negatives:   14\tTrue negatives:  124\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 339
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PERF_FORMAT_STRING = \"\\\n",
      "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
      "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
      "\n",
      "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
      "\n",
      "accuracy = []\n",
      "precision = []\n",
      "recall = []\n",
      "f1 = []\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True)\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "#skf = StratifiedKFold(labels, n_folds=6)\n",
      "cv = StratifiedShuffleSplit(labels, 10, random_state = 42)\n",
      "#cv = KFold( len(labels), 6, shuffle=False, random_state=None)\n",
      "\n",
      "selector = SelectKBest(f_classif, k=4)\n",
      "#selector = SelectPercentile(f_classif, percentile=5)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "true_negatives = 0\n",
      "false_negatives = 0\n",
      "true_positives = 0\n",
      "false_positives = 0\n",
      "count = 0\n",
      "for train_indices, test_indices in cv:\n",
      "    features_train = []\n",
      "    features_test = []\n",
      "    word_features_train = []\n",
      "    word_features_test = []\n",
      "    labels_train = []\n",
      "    labels_test = []\n",
      "    \n",
      "    \n",
      "    '''\n",
      "    for ii in train_idx:\n",
      "        features_train.append(features[ii])\n",
      "        word_features_train.append(word_data[ii])\n",
      "        labels_train.append(labels[ii])\n",
      "    for jj in test_idx:\n",
      "        features_test.append(features[jj])\n",
      "        word_features_test.append(word_data[jj])\n",
      "        labels_test.append(labels[jj])\n",
      "    '''\n",
      "    \n",
      "    ### Partitioning of the data into training and testing datasets\n",
      "    \n",
      "    features_train = [features[ii] for ii in train_indices]\n",
      "    #word_features_train = [word_data[ii] for ii in train_indices]\n",
      "    labels_train = [labels[ii] for ii in train_indices]\n",
      "       \n",
      "    features_test = [features[jj] for jj in test_indices]\n",
      "    #word_features_test = [word_data[jj] for jj in test_indices]\n",
      "    labels_test = [labels[jj] for jj in test_indices]\n",
      "        \n",
      "    ### Fitting and transformation of the training dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_train = vectorizer.fit_transform(word_features_train).toarray()\n",
      "    #features_train = np.hstack((features_train, word_features_train))\n",
      "    \n",
      "    features_train = scaler.fit_transform(features_train)\n",
      "    \n",
      "    features_train = selector.fit_transform(features_train, labels_train)\n",
      "    \n",
      "    ### Transformation of the test dataset (vectorizer, scaling, feature selection)\n",
      "    \n",
      "    #word_features_test = vectorizer.transform(word_features_test).toarray()\n",
      "    #features_test = np.hstack((features_test, word_features_test))\n",
      "    \n",
      "    features_test = scaler.transform(features_test)\n",
      "    \n",
      "    features_test = selector.transform(features_test)\n",
      "\n",
      "    ### Training the classifer\n",
      "    \n",
      "    '''\n",
      "    ada = AdaBoostClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50], 'algorithm' : ['SAMME.R']}\n",
      "    clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    parameters = {'criterion':('gini', 'entropy'), 'max_features':('auto', 'sqrt', 'log2'), 'random_state': [1, 50]}\n",
      "    dt = DecisionTreeClassifier()\n",
      "    clf = GridSearchCV(dt, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    print dt.feature_importances_\n",
      "    \n",
      "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "    svr = SVC()\n",
      "    clf = GridSearchCV(svr, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    clf = GaussianNB()\n",
      "    #parameters = {'n_estimators': [1, 100], 'random_state': [1, 50]}\n",
      "    #clf = GridSearchCV(ada, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    '''\n",
      "    rfc = RandomForestClassifier()\n",
      "    parameters = {'n_estimators': [1, 200], 'random_state': [1, 50]}\n",
      "    clf = GridSearchCV(rfc, parameters)\n",
      "    clf.fit(features_train, labels_train)\n",
      "    pred = clf.predict(features_test)\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    ### Evaluating performance metrics\n",
      "    \n",
      "    #print \"Accuracy: \", clf.score(features_test, labels_test)\n",
      "    #print \"Precision: \", precision_score(labels_test, pred)\n",
      "    #print \"Recall: \", recall_score(labels_test, pred)\n",
      "    #print \"F1_Score: \", f1_score(labels_test, pred)\n",
      "    \n",
      "    for prediction, truth in zip(pred, labels_test):\n",
      "        if prediction == 0 and truth == 0:\n",
      "            true_negatives += 1\n",
      "        elif prediction == 0 and truth == 1:\n",
      "            false_negatives += 1\n",
      "        elif prediction == 1 and truth == 0:\n",
      "            false_positives += 1\n",
      "        else:\n",
      "            true_positives += 1\n",
      "    count += 1\n",
      "    print count\n",
      "\n",
      "try:\n",
      "    total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
      "\n",
      "    accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
      "\n",
      "    precision = 1.0*true_positives/(true_positives+false_positives)\n",
      "\n",
      "    recall = 1.0*true_positives/(true_positives+false_negatives)\n",
      "\n",
      "    f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
      "\n",
      "    f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
      "\n",
      "    print clf\n",
      "    print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
      "    print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
      "    print \"\"\n",
      "except:\n",
      "    print \"Got a divide by zero when trying out:\", clf\n",
      "    '''\n",
      "    accuracy.append(clf.score(features_test, labels_test))\n",
      "    precision.append(precision_score(labels_test, pred))\n",
      "    recall.append(recall_score(labels_test, pred))\n",
      "    f1.append(f1_score(labels_test, pred))\n",
      "    '''\n",
      "#print \"Average accuracy: \", sum(accuracy) / 6\n",
      "#print \"Average precision: \", sum(precision) / 6\n",
      "#print \"Average recall: \", sum(recall) / 6\n",
      "#print \"Average f1_score: \", sum(f1) / 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 200], 'random_state': [1, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "\tAccuracy: 0.86667\tPrecision: 0.50000\tRecall: 0.30000\tF1: 0.37500\tF2: 0.32609\n",
        "\tTotal predictions:  150\tTrue positives:    6\tFalse positives:    6\tFalse negatives:   14\tTrue negatives:  124\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-83-4f0731f47a27>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-83-4f0731f47a27>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install pymc\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}